# **Rehash 过程**

## **I. 普通 Rehash 重新散列**

哈希表保存的键值对数量是动态变化的，为了让哈希表的负载因子维持在一个合理的范围之内，就需要对哈希表进行扩缩容。

扩缩容是通过执行**rehash重新散列**来完成，对字典的哈希表执行普通rehash的基本步骤为**分配空间->逐个迁移->交换哈希表**，详细过程如下：

1. 为字典的ht[1]哈希表分配空间，分配的空间大小取决于要执行的操作以及ht[0]当前包含的键值对数量：
    扩展操作时ht[1]的大小为第一个大于等于ht[0].used*2的2^n；
    收缩操作时ht[1]的大小为第一个大于等于ht[0].used的2^n；
    扩展时比如h[0].used=200，那么需要选择大于400的第一个2的幂，也就是2^9=512。

2. 将保存在ht[0]中的所有键值对重新计算键的哈希值和索引值rehash到ht[1]上；

3. 重复rehash直到ht[0]包含的所有键值对全部迁移到了ht[1]之后释放 ht[0]，**将ht[1]设置为 ht[0]**，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。

## **II. 渐进Rehash过程**

Redis的rehash动作并不是一次性完成的，而是**分多次、渐进式**地完成的，原因在于当哈希表里保存的键值对数量很大时，一次性将这些键值对全部rehash到ht[1]可能会导致服务器在一段时间内停止服务，这个是无法接受的。

针对这种情况Redis采用了渐进式rehash，过程的详细步骤：

1. 为ht[1]分配空间，这个过程和普通Rehash没有区别；

2. 将rehashidx设置为0，表示rehash工作正式开始，同时这个rehashidx是递增的，从0开始表示从数组第一个元素开始rehash。

3. 在rehash进行期间，每次对字典**执行增删改查操作时**，顺带将ht[0]哈希表在rehashidx索引上的键值对rehash到 ht[1]，完成后将rehashidx加1，指向下一个需要rehash的键值对。

4. 随着字典操作的不断执行，最终ht[0]的所有键值对都会被rehash至ht[1]，再将rehashidx属性的值设为-1来表示 rehash 操作已完成。

渐进式 rehash 的思想在于将rehash键值对所需的计算工作分散到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的阻塞问题。

看到这里不禁去想**这种捎带脚式的 rehash 会不会导致整个过程非常漫长**？如果某个 value 一直没有操作那么需要扩容时由于一直不用所以影响不大，需要缩容时如果一直不处理可能造成内存浪费，具体的还没来得及研究，先埋个问题吧！